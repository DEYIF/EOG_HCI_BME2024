'''1ç»´CNN'''
'''2024.06.02'''

# è¯»å– .mat æ–‡ä»¶




import scipy.io
import numpy as np
import torch
import torch.nn as nn
import torch.optim as optim
from torch.utils.data import DataLoader, TensorDataset, random_split
from sklearn.preprocessing import LabelEncoder
from sklearn.metrics import classification_report
def load_mat_file(filepath):
    mat = scipy.io.loadmat(filepath)
    # å‡è®¾æ–‡ä»¶ä¸­æœ‰ä¸€ä¸ªåä¸º 'data' çš„å˜é‡ï¼Œè¿™é‡Œéœ€è¦æ ¹æ®å®é™
æ–‡ä»¶ä¸­çš„å˜é‡åè°ƒæ•´
    data = mat['data']
    return data

# åŠ è½½æ‰€æœ‰åŠ¨ä½œæ–‡ä»¶çš„æ•°æ®å¹¶ç”Ÿæˆæ ‡ç­¾


def load_all_data(files):
    data_list = []
    labels_list = []
    for idx, file in enumerate(files):
        data = load_mat_file(file)
        # æ ¹æ®å®é™
æ•°æ®å½¢çŠ¶è°ƒæ•´è¿™é‡Œçš„å¤„ç†æ–¹å¼
        data_list.append(data)
        labels_list.append(np.full(data.shape[0], idx))

    data = np.concatenate(data_list, axis=0)
    labels = np.concatenate(labels_list, axis=0)
    return data, labels


# ç¤ºä¾‹æ–‡ä»¶åˆ—è¡¨ï¼ˆè¯·æ›¿æ¢ä¸ºå®é™
æ–‡ä»¶è·¯å¾„ï¼‰
files = [
    'E:/æ¡Œé¢/ç«èµ›ã€ç ”å­¦ã€è¯„å¥–è¯„ä¼˜/2024ç”ŸåŒ»å·¥å›½èµ›/data/up_tailor_raw.mat',
    'E:/æ¡Œé¢/ç«èµ›ã€ç ”å­¦ã€è¯„å¥–è¯„ä¼˜/2024ç”ŸåŒ»å·¥å›½èµ›/data/down_tailor_raw.mat',
    'E:/æ¡Œé¢/ç«èµ›ã€ç ”å­¦ã€è¯„å¥–è¯„ä¼˜/2024ç”ŸåŒ»å·¥å›½èµ›/data/left_tailor_raw.mat',
    'E:/æ¡Œé¢/ç«èµ›ã€ç ”å­¦ã€è¯„å¥–è¯„ä¼˜/2024ç”ŸåŒ»å·¥å›½èµ›/data/right_tailor_raw.mat',
    'E:/æ¡Œé¢/ç«èµ›ã€ç ”å­¦ã€è¯„å¥–è¯„ä¼˜/2024ç”ŸåŒ»å·¥å›½èµ›/data/wink_tailor_raw.mat'
]

# åŠ è½½æ•°æ®
data, labels = load_all_data(files)
# %%
# æ•°æ®å½¢çŠ¶è°ƒæ•´ä¸º (num_samples, signal_length)
signal_length = data.shape[1]

# æ ‡ç­¾ç¼–ç 
label_encoder = LabelEncoder()
labels = label_encoder.fit_transform(labels)

# è½¬æ¢ä¸ºPyTorchå¼ é‡
data_tensor = torch.tensor(data, dtype=torch.float32)
labels_tensor = torch.tensor(labels, dtype=torch.int64)

# åˆ›å»ºTensorDataset
dataset = TensorDataset(data_tensor, labels_tensor)

# æ‹†åˆ†è®­ç»ƒé›†å’Œæµ‹è¯•é›†
train_size = int(0.8 * len(dataset))
test_size = len(dataset) - train_size
train_dataset, test_dataset = random_split(dataset, [train_size, test_size])

# åˆ›å»ºDataLoader
batch_size = 32
train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)
test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)

# å®šä¹‰1D CNNæ¨¡å‹


class CNN1D(nn.Module):
    def __init__(self, num_classes):
        super(CNN1D, self).__init__()
        self.conv1 = nn.Conv1d(in_channels=1, out_channels=64, kernel_size=3)
        self.pool = nn.MaxPool1d(kernel_size=2)
        self.conv2 = nn.Conv1d(in_channels=64, out_channels=128, kernel_size=3)
        # è®¡ç®—å
¬å¼ï¼š((signal_length - kernel_size + 1) // pool_size)
        self.fc1 = nn.Linear(128 * ((signal_length - 4) // 4), 128)
        self.fc2 = nn.Linear(128, num_classes)

    def forward(self, x):
        x = self.pool(torch.relu(self.conv1(x)))
        x = self.pool(torch.relu(self.conv2(x)))
        x = x.view(-1, 128 * ((signal_length - 4) // 4))
        x = torch.relu(self.fc1(x))
        x = self.fc2(x)
        return x


# åˆå§‹åŒ–æ¨¡å‹ã€æŸå¤±å‡½æ•°å’Œä¼˜åŒ–å™¨
num_classes = len(files)
model = CNN1D(num_classes=num_classes)
criterion = nn.CrossEntropyLoss()
optimizer = optim.Adam(model.parameters(), lr=0.001)

# è®­ç»ƒæ¨¡å‹
num_epochs = 10

for epoch in range(num_epochs):
    model.train()
    running_loss = 0.0
    for inputs, labels in train_loader:
        inputs = inputs.unsqueeze(1)  # å¢åŠ é€šé“ç»´åº¦

        optimizer.zero_grad()
        outputs = model(inputs)
        loss = criterion(outputs, labels)
        loss.backward()
        optimizer.step()

        running_loss += loss.item() * inputs.size(0)

    epoch_loss = running_loss / train_size
    print(f'Epoch {epoch+1}/{num_epochs}, Loss: {epoch_loss:.4f}')

# ä¿å­˜æ¨¡å‹
model_path = 'eye_signal_cnn_model.pth'
torch.save(model.state_dict(), model_path)
print(f'Model saved to {model_path}')

# åŠ è½½æ¨¡å‹
model = CNN1D(num_classes=num_classes)
model.load_state_dict(torch.load(model_path))
model.eval()  # è®¾ç½®ä¸ºè¯„ä¼°æ¨¡å¼
print('Model loaded and ready for inference')


def get_real_time_data():
    # è¿™æ˜¯ä¸€ä¸ªç¤ºä¾‹å‡½æ•°ï¼Œåº”æ ¹æ®å®é™
æƒ
å†µå®ç°
    # å‡è®¾è¿”å›ä¸€ä¸ªå½¢çŠ¶ä¸º (signal_length,) çš„ numpy æ•°ç»„
    return np.random.rand(signal_length).astype(np.float32)


# å®æ—¶æ•°æ®åˆ†ç±»
real_time_data = get_real_time_data()
real_time_data_tensor = torch.tensor(real_time_data).unsqueeze(
    0).unsqueeze(0)  # è½¬æ¢ä¸º (1, 1, signal_length) çš„å¼ é‡

with torch.no_grad():
    output = model(real_time_data_tensor)
    _, predicted_label = torch.max(output, 1)

print(f'Predicted label for real-time data: {predicted_label.item()}')
